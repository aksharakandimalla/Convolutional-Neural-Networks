{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cats_vs_dogs(transfer_learning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM2Dcg+3iLK4WUGQmpaVzJT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aksharakandimalla/Convolutional-Neural-Networks/blob/master/cats_vs_dogs(transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLnxMR6UcSIU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "10d159a5-0835-4795-f005-b1cf76610ccd"
      },
      "source": [
        "import os\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "pre_trained_model = InceptionV3(\n",
        "                                        input_shape = (150,150,3),\n",
        "                                        include_top = False,\n",
        "                                        weights = None\n",
        "\n",
        ")\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "#pre_trained_model.summary()\n",
        "\n",
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('the shape of the last layer is', last_layer.output_shape)\n",
        "last_output = last_layer.output"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-11 12:25:38--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.142.128, 74.125.195.128, 74.125.20.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.142.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M  85.1MB/s    in 1.0s    \n",
            "\n",
            "2020-08-11 12:25:39 (85.1 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "the shape of the last layer is (None, 7, 7, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXn7rvjfgQJ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "x = layers.Flatten()(last_output)\n",
        "x = layers.Dense(1024,activation = 'relu')(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "x = layers.Dense(1,activation='sigmoid')(x)\n",
        "\n",
        "model = Model(pre_trained_model.input, x)\n",
        "model.compile(optimizer = RMSprop(lr = 0.0001), loss = 'binary_crossentropy', metrics = 'accuracy')\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjkJ5Vj_jByh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "0954397e-5c4f-4fd3-bf34-dc71af7aac94"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "        https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "       -O /tmp/cats_and_dogs_filtered.zip"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-11 12:57:43--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.28.128, 74.125.142.128, 74.125.195.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.28.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68606236 (65M) [application/zip]\n",
            "Saving to: ‘/tmp/cats_and_dogs_filtered.zip’\n",
            "\n",
            "/tmp/cats_and_dogs_ 100%[===================>]  65.43M  92.6MB/s    in 0.7s    \n",
            "\n",
            "2020-08-11 12:57:44 (92.6 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8XTz0imjDGT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/cats_and_dogs_filtered.zip'\n",
        "\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n",
        "\n",
        "# Define our example directories and files\n",
        "base_dir = '/tmp/cats_and_dogs_filtered'\n",
        "\n",
        "train_dir = os.path.join( base_dir, 'train')\n",
        "validation_dir = os.path.join( base_dir, 'validation')\n",
        "\n",
        "\n",
        "train_cats_dir = os.path.join(train_dir, 'cats') # Directory with our training cat pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs') # Directory with our training dog pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats') # Directory with our validation cat pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')# Directory with our validation dog pictures\n",
        "\n",
        "train_cat_fnames = os.listdir(train_cats_dir)\n",
        "train_dog_fnames = os.listdir(train_dogs_dir)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvX3B2a4lzif",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "c49b9ecf-e045-4350-da19-9bf7322c4fb8"
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "                                      rescale = 1./255,\n",
        "                                      rotation_range = 40,\n",
        "                                      width_shift_range = 0.2,\n",
        "                                      height_shift_range = 0.2,\n",
        "                                      zoom_range = 0.2,\n",
        "                                      shear_range = 0.2,\n",
        "                                      horizontal_flip = True\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "                                                      train_dir,\n",
        "                                                      batch_size = 20,\n",
        "                                                      class_mode = 'binary',\n",
        "                                                      target_size = (150,150))\n",
        "\n",
        "validation_datagen = ImageDataGenerator(\n",
        "                                      rescale = 1./255\n",
        ")\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "                                                      validation_dir,\n",
        "                                                      batch_size = 20,\n",
        "                                                      class_mode = 'binary',\n",
        "                                                      target_size = (150,150)\n",
        ")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hwJmC67q2Kf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        },
        "outputId": "6a766126-a7df-4bc5-a537-1b6049f8c177"
      },
      "source": [
        "history = model.fit_generator(\n",
        "                                    train_generator, validation_data = validation_generator, steps_per_epoch = 100, epochs = 20, validation_steps = 50, verbose = 2\n",
        ")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "100/100 - 152s - loss: 0.2368 - accuracy: 0.9105 - val_loss: 0.0958 - val_accuracy: 0.9590\n",
            "Epoch 2/20\n",
            "100/100 - 154s - loss: 0.1807 - accuracy: 0.9295 - val_loss: 0.0982 - val_accuracy: 0.9640\n",
            "Epoch 3/20\n",
            "100/100 - 151s - loss: 0.1883 - accuracy: 0.9295 - val_loss: 0.1175 - val_accuracy: 0.9650\n",
            "Epoch 4/20\n",
            "100/100 - 151s - loss: 0.1816 - accuracy: 0.9425 - val_loss: 0.1766 - val_accuracy: 0.9580\n",
            "Epoch 5/20\n",
            "100/100 - 150s - loss: 0.1999 - accuracy: 0.9305 - val_loss: 0.1052 - val_accuracy: 0.9620\n",
            "Epoch 6/20\n",
            "100/100 - 154s - loss: 0.1849 - accuracy: 0.9320 - val_loss: 0.1187 - val_accuracy: 0.9700\n",
            "Epoch 7/20\n",
            "100/100 - 151s - loss: 0.1728 - accuracy: 0.9350 - val_loss: 0.1730 - val_accuracy: 0.9520\n",
            "Epoch 8/20\n",
            "100/100 - 151s - loss: 0.1473 - accuracy: 0.9545 - val_loss: 0.1368 - val_accuracy: 0.9590\n",
            "Epoch 9/20\n",
            "100/100 - 151s - loss: 0.1767 - accuracy: 0.9440 - val_loss: 0.1375 - val_accuracy: 0.9590\n",
            "Epoch 10/20\n",
            "100/100 - 154s - loss: 0.1463 - accuracy: 0.9520 - val_loss: 0.1591 - val_accuracy: 0.9600\n",
            "Epoch 11/20\n",
            "100/100 - 150s - loss: 0.1577 - accuracy: 0.9530 - val_loss: 0.1064 - val_accuracy: 0.9650\n",
            "Epoch 12/20\n",
            "100/100 - 151s - loss: 0.1436 - accuracy: 0.9540 - val_loss: 0.0987 - val_accuracy: 0.9680\n",
            "Epoch 13/20\n",
            "100/100 - 151s - loss: 0.1302 - accuracy: 0.9550 - val_loss: 0.1140 - val_accuracy: 0.9670\n",
            "Epoch 14/20\n",
            "100/100 - 154s - loss: 0.1500 - accuracy: 0.9490 - val_loss: 0.1779 - val_accuracy: 0.9520\n",
            "Epoch 15/20\n",
            "100/100 - 150s - loss: 0.1280 - accuracy: 0.9560 - val_loss: 0.1833 - val_accuracy: 0.9500\n",
            "Epoch 16/20\n",
            "100/100 - 150s - loss: 0.1428 - accuracy: 0.9455 - val_loss: 0.1686 - val_accuracy: 0.9530\n",
            "Epoch 17/20\n",
            "100/100 - 150s - loss: 0.1189 - accuracy: 0.9630 - val_loss: 0.2400 - val_accuracy: 0.9460\n",
            "Epoch 18/20\n",
            "100/100 - 153s - loss: 0.1414 - accuracy: 0.9545 - val_loss: 0.1345 - val_accuracy: 0.9600\n",
            "Epoch 19/20\n",
            "100/100 - 149s - loss: 0.1453 - accuracy: 0.9565 - val_loss: 0.1507 - val_accuracy: 0.9570\n",
            "Epoch 20/20\n",
            "100/100 - 149s - loss: 0.1155 - accuracy: 0.9630 - val_loss: 0.1167 - val_accuracy: 0.9640\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNYzV90ksfLI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "ddd1533d-8891-4593-bdbb-b5269d089896"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "test_accuracy = history.history['accuracy']\n",
        "validation_accuracy = history.history['val_accuracy']\n",
        "test_loss = history.history['loss']\n",
        "validation_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "plt.plot(epochs, test_accuracy, 'r', label = 'test-accuracy')\n",
        "plt.plot(epochs, validation_accuracy, 'b', label = 'val-accuracy')\n",
        "plt.title('accuracy comparisson')\n",
        "plt.legend(loc = 0)\n",
        "plt.figure()\n",
        "plt.show()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-5796d7adf987>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mvalidation_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'test-accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'val-accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'acc' is not defined"
          ]
        }
      ]
    }
  ]
}